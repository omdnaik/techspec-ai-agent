[
  {
    "title": "Overview",
    "content": "This system processes financial deal files through a multi-stage asynchronous pipeline using Spring Boot. The pipeline includes parsing, processing, and XML generation phases. Each stage operates with its own executor and can handle tasks concurrently while maintaining deal-level sequential consistency."
  },
  {
    "title": "Component/Class Overview",
    "content": "| Component                       | Responsibility                                                               |\n| ------------------------------- | ---------------------------------------------------------------------------- |\n| FileWatcherService              | Monitors directories for new files and initiates processing.                 |\n| FileProcessorService            | Parses raw deal files and extracts identifiers.                              |\n| DealProcessorService            | Transforms parsed deal data using business rules.                            |\n| XmlGeneratorService             | Converts transformed data into the final XML format.                         |\n| ConsistentHashingTaskExecutor  | Ensures all tasks for a single deal go to the same single-threaded executor. |\n| DealFileQueueManager           | Queues and serializes processing of files per deal.                          |\n| LoggingConfig                  | Sets up executor-based and thread-based loggers.                             |"
  },
  {
    "title": "Threading & Concurrency Design",
    "content": "- Each major component uses a dedicated ThreadPoolTaskExecutor.\n- The ConsistentHashingTaskExecutor hashes dealId to one of N single-threaded executors.\n- MDC and TaskDecorator are used to propagate logging context.\n- Executors use CallerRunsPolicy to avoid silent task drops."
  },
  {
    "title": "Directory & File Flow",
    "content": "| Deal Status  | Source Dir       | Destination Dir  |\n| ------------ | ---------------- | ---------------- |\n| RECEIVED     | /input           | /tmp             |\n| DEAL_READY   | /tmp             | /fileprocessed   |\n| PROCESSED    | /fileprocessed   | /xml             |\n| ERROR        | Any              | /error           |"
  },
  {
    "title": "Special Case: DEAL_READY",
    "content": "- From FileProcessorService: Move from /tmp \u2192 /fileprocessed.\n- From DealProcessorService: Move from /fileprocessed \u2192 /tmp."
  },
  {
    "title": "Status Routing Logic",
    "content": "public enum DealStatus {\n    DEAL_READY {\n        public Path getSource(ProcessingStage stage) {\n            return stage == FILE_PROCESSING ? TMP : FILE_PROCESSED;\n        }\n        public Path getDestination(ProcessingStage stage) {\n            return stage == FILE_PROCESSING ? FILE_PROCESSED : TMP;\n        }\n    }\n    // ... other statuses\n}"
  },
  {
    "title": "Logging Strategy",
    "content": "- Executors are prefixed (e.g., dealExecutor-1, fileExecutor-1).\n- MDC stores threadName as dealThread.\n- Sifting Appender writes logs per thread to logs/dealExecutor-1.log, etc.\n- ConsumerExecutor logs are routed via MDC propagation."
  },
  {
    "title": "Performance Targets",
    "content": "- Files: 10,000\n- Duration: 8 hours\n- Target: ~300 files/minute\n- Threads per stage: Max 5 (configurable)\n- Deal-level concurrency: Sequential per deal"
  },
  {
    "title": "Key Constraints",
    "content": "- Spring Boot batch job (non-web)\n- Spring JDBC with HikariCP\n- Spring Boot starter for Jersey REST (for optional APIs)\n- Conditional secondary DB (enabled by XML property at startup)\n- Not using Spring Batch"
  },
  {
    "title": "Error Handling & Recovery",
    "content": "- Exceptions during processing are caught and status is set to ERROR\n- Files moved to /error dir\n- Overflow events from WatchService trigger fallback sync\n- Fallback sync avoids re-queuing already queued files"
  },
  {
    "title": "Java Watcher Overflow Handling",
    "content": "- Queue overflow is expected under high volume\n- Uses fallback sync thread to scan and enqueue files manually\n- Files already in executor queues are skipped"
  },
  {
    "title": "Logging Pipeline Flow",
    "content": "DealExecutor \u2192 submits \u2192 ConsumerExecutor\n           \u21b3 MDC Decorator adds dealThread\nConsumerExecutor \u21b3 inherits MDC context\nLogs from both go to logs/dealExecutor-<X>.log"
  },
  {
    "title": "Suggestions for Future Enhancements",
    "content": "- Replace DB polling with Event-Driven messaging\n- Introduce in-memory state coordination (e.g., Redis/MapDB)\n- Explore batching file tasks by deal instead of individual\n- Log-level telemetry using Micrometer + Grafana dashboards"
  },
  {
    "title": "Monitoring & Observability",
    "content": "- Thread counts, queue sizes, rejection metrics (via custom meters)\n- Log volume per deal executor\n- Async appender health\n- Disk I/O during fallback sync"
  }
]